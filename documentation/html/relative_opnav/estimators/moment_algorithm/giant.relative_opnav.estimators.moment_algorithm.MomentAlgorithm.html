
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>MomentAlgorithm &#8212; GIANT 1.0.0 documentation</title>
    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/alabaster.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/graphviz.css" />
    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <link rel="shortcut icon" href="../../../_static/logo.ico"/>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="copyright" title="Copyright" href="../../../copyright.html" />
    <link rel="next" title="MomentAlgorithm.compute_line_of_sight_sun_image" href="giant.relative_opnav.estimators.moment_algorithm.MomentAlgorithm.compute_line_of_sight_sun_image.html" />
    <link rel="prev" title="moment_algorithm" href="../giant.relative_opnav.estimators.moment_algorithm.html" />
   
  <link rel="stylesheet" href="../../../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  <div class="document">
    
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<p class="logo">
  <a href="../../../index.html">
    <img class="logo" src="../../../_static/logo.png" alt="Logo"/>
    
  </a>
</p>



<p class="blurb">A powerful API for Optical Navigation</p>






<h3>Navigation</h3>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../../installation.html">Installing GIANT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../getting_started.html">Getting Started</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../../../giant.html">API Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../giant.html#indices">Indices</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../license.html">License</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../copyright.html">Copyright</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../../index.html">Documentation overview</a><ul>
  <li><a href="../../../giant.html">API Reference</a><ul>
  <li><a href="../../../giant.relative_opnav.html">giant.relative_opnav</a><ul>
  <li><a href="../../giant.relative_opnav.estimators.html">estimators</a><ul>
  <li><a href="../giant.relative_opnav.estimators.moment_algorithm.html">moment_algorithm</a><ul>
      <li>Previous: <a href="../giant.relative_opnav.estimators.moment_algorithm.html" title="previous chapter">moment_algorithm</a></li>
      <li>Next: <a href="giant.relative_opnav.estimators.moment_algorithm.MomentAlgorithm.compute_line_of_sight_sun_image.html" title="next chapter">MomentAlgorithm.compute_line_of_sight_sun_image</a></li>
  </ul></li>
  </ul></li>
  </ul></li>
  </ul></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="documentwrapper">
        <div class="bodywrapper">
              <div class="related top">
                &nbsp;
  <nav id="rellinks">
    <ul>
        <li>
          &larr;
          <a href="../giant.relative_opnav.estimators.moment_algorithm.html" title="Previous document">moment_algorithm</a>
        </li>
        <li>
          <a href="giant.relative_opnav.estimators.moment_algorithm.MomentAlgorithm.compute_line_of_sight_sun_image.html" title="Next document">MomentAlgorithm.compute_line_of_sight_sun_image</a>
          &rarr;
        </li>
    </ul>
  </nav>
              </div>
          

          <div class="body" role="main">
            
  <section id="momentalgorithm">
<h1>MomentAlgorithm<a class="headerlink" href="#momentalgorithm" title="Permalink to this headline">¶</a></h1>
<p><a class="reference internal" href="../giant.relative_opnav.estimators.moment_algorithm.html#module-giant.relative_opnav.estimators.moment_algorithm" title="giant.relative_opnav.estimators.moment_algorithm"><code class="xref py py-mod docutils literal notranslate"><span class="pre">giant.relative_opnav.estimators.moment_algorithm</span></code></a>:</p>
<dl class="py class">
<dt class="sig sig-object py" id="giant.relative_opnav.estimators.moment_algorithm.MomentAlgorithm">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">giant.relative_opnav.estimators.moment_algorithm.</span></span><span class="sig-name descname"><span class="pre">MomentAlgorithm</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">scene</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">camera</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">image_processing</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_apparent_area</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">apparent_area_margin_of_safety</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">search_distance</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">apply_phase_correction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">phase_correction_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">PhaseCorrectionType.SIMPLE</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">brdf</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/giant/relative_opnav/estimators/moment_algorithm.html#MomentAlgorithm"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#giant.relative_opnav.estimators.moment_algorithm.MomentAlgorithm" title="Permalink to this definition">¶</a></dt>
<dd><p>This class implements GIANT’s version of moment based center finding for extracting bearing measurements to resolved
or or unresolved targets in an image.</p>
<p>The class provides an interface to perform moment based center for each target body that is predicted to be in an
image.  It does this by looping through each target object contained in the <a class="reference internal" href="../../../ray_tracer/scene/giant.ray_tracer.scene.Scene.html#giant.ray_tracer.scene.Scene.target_objs" title="giant.ray_tracer.scene.Scene.target_objs"><code class="xref py py-attr docutils literal notranslate"><span class="pre">Scene.target_objs</span></code></a> attribute
that is is requested.  For each of the targets, the algorithm:</p>
<ol class="arabic simple">
<li><p>Predicts the location of the target in the image using the a priori knowledge of the scene</p></li>
<li><p>Predicts the apparent area of the target in the scene assuming a spherical target.</p></li>
<li><p>Segments the image into foreground/background objects using the smallest expected apparent area of all
targets as the minimum segment area.  This is done using <code class="xref py py-meth docutils literal notranslate"><span class="pre">ImageProcessing.segment_image()</span></code></p></li>
<li><p>Identifies the closest foreground segment to the predicted target location that is also within the user
specified search radius.  If the closest segment is also the closest segment for another target in the image,
then both targets are recorded as not found.  If no segments are within the search radius of the predicted
target center then the target is marked as not found.</p></li>
<li><p>Takes the foreground objects around the identified segment and finds the centroid of the illuminated areas
using a moment algorithm to compute the observed center of brightness.</p></li>
<li><p>If requested, corrects the observed center of brightness to the observed center of figure using the
<a class="reference internal" href="giant.relative_opnav.estimators.moment_algorithm.MomentAlgorithm.compute_phase_correction.html#giant.relative_opnav.estimators.moment_algorithm.MomentAlgorithm.compute_phase_correction" title="giant.relative_opnav.estimators.moment_algorithm.MomentAlgorithm.compute_phase_correction"><code class="xref py py-meth docutils literal notranslate"><span class="pre">compute_phase_correction()</span></code></a>.</p></li>
</ol>
<p>For more details on the image segmentation, along with possible tuning parameters, refer to the
<code class="xref py py-meth docutils literal notranslate"><span class="pre">ImageProcessing.segment_image()</span></code> documentation.</p>
<p>The search radius is controlled by <code class="xref py py-attr docutils literal notranslate"><span class="pre">search_distance</span></code> attribute.  This should be a number or <code class="docutils literal notranslate"><span class="pre">None</span></code>.
If this is not <code class="docutils literal notranslate"><span class="pre">None</span></code>, then the distance from the centroid of the nearest segment to the predicted target u
location must be less than this value.  Therefore, you should set this value to account for the expected
center-of-figure to center-of-brightness shift as well as the uncertainty in the a priori location of the target
in the scene, while being careful not to set too large of a value if there are multiple targets in the scene to
avoid ambiguity.  If this is <code class="docutils literal notranslate"><span class="pre">None</span></code>, then the closest segment is always paired with the target (there is no
search region considered) unless the segment has already been paired to another target in the scene.</p>
<p>This technique can predict what the minimum segment area should be in the image using the predicted apparent areas
for each target.  This can be useful to automatically set the <code class="xref py py-attr docutils literal notranslate"><span class="pre">ImageProcessing.minimum_segment_area</span></code> based on
the targets and the a priori location in the camera frame.  Because this is just an approximation, a margin of
safety is included with <code class="xref py py-attr docutils literal notranslate"><span class="pre">apparent_area_margin_of_safety</span></code>, which is used to shrink the predicted apparent area
to account for the assumptions about the spherical target and possible errors in the a priori scene information.
You can turn off this feature and just use the set minimum segment area by setting <code class="xref py py-attr docutils literal notranslate"><span class="pre">use_apparent_area</span></code> to
<code class="docutils literal notranslate"><span class="pre">False</span></code>.</p>
<p>Whether the phase correction is applied or not is controlled by the boolean flag <code class="xref py py-attr docutils literal notranslate"><span class="pre">apply_phase_correction</span></code>.
The information that is passed to the phase correction routines are controlled by the <code class="xref py py-attr docutils literal notranslate"><span class="pre">phase_correction_type</span></code>
and <code class="xref py py-attr docutils literal notranslate"><span class="pre">brdf</span></code> attributes.</p>
<p>When all of the required data has been successfully loaded into an instance of this class, the <a class="reference internal" href="giant.relative_opnav.estimators.moment_algorithm.MomentAlgorithm.estimate.html#giant.relative_opnav.estimators.moment_algorithm.MomentAlgorithm.estimate" title="giant.relative_opnav.estimators.moment_algorithm.MomentAlgorithm.estimate"><code class="xref py py-meth docutils literal notranslate"><span class="pre">estimate()</span></code></a>
method is used to extract the observed centers of the target bodies predicted to be in the requested image.  The
results are stored into the <code class="xref py py-attr docutils literal notranslate"><span class="pre">observed_bearings</span></code> attribute. In addition, the predicted location for each target
is stored in the <code class="xref py py-attr docutils literal notranslate"><span class="pre">computed_bearings</span></code> attribute. Finally, the details about the fit are stored as a
dictionary in the appropriate element in the <code class="xref py py-attr docutils literal notranslate"><span class="pre">details</span></code> attribute.  Specifically, these dictionaries will
contain the following keys.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 19%" />
<col style="width: 81%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Key</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">'Fit'</span></code></p></td>
<td><p>The fit moment object.  Only available if successful.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">'Phase</span> <span class="pre">Correction'</span></code></p></td>
<td><p>The phase correction vector used to convert from center of brightness to center of figure.
This will only be available if the fit was successful.  If <code class="xref py py-attr docutils literal notranslate"><span class="pre">apply_phase_correction</span></code> is
<code class="docutils literal notranslate"><span class="pre">False</span></code> then this will be an array of 0.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">'Observed</span> <span class="pre">Area'</span></code></p></td>
<td><p>The area (number of pixels that were considered foreground) observed for this target.
This is only available if the fit was successful.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">'Predicted</span> <span class="pre">Area'</span></code></p></td>
<td><p>The area (number of pixels that were considered foreground) predicted for this target.
This is only available if the fit was successful.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">'Failed'</span></code></p></td>
<td><p>A message indicating why the fit failed.  This will only be present if the fit failed (so you
could do something like <code class="docutils literal notranslate"><span class="pre">'Failed'</span> <span class="pre">in</span> <span class="pre">moment_algorithm.details[target_ind]</span></code> to check if
something failed.  The message should be a human readable description of what called the
failure.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">'Found</span> <span class="pre">Segments'</span></code></p></td>
<td><p>All of the segments that were found in the image.  This is a tuple of all of the returned
values from <code class="xref py py-meth docutils literal notranslate"><span class="pre">ImageProcessing.segment_image()</span></code>.  This is only included if the fit failed
for some reason.</p></td>
</tr>
</tbody>
</table>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Before calling the <a class="reference internal" href="giant.relative_opnav.estimators.moment_algorithm.MomentAlgorithm.estimate.html#giant.relative_opnav.estimators.moment_algorithm.MomentAlgorithm.estimate" title="giant.relative_opnav.estimators.moment_algorithm.MomentAlgorithm.estimate"><code class="xref py py-meth docutils literal notranslate"><span class="pre">estimate()</span></code></a> method be sure that the scene has been updated to correspond to the correct
image time.  This class does not update the scene automatically.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>scene</strong> (<a class="reference internal" href="../../../ray_tracer/scene/giant.ray_tracer.scene.Scene.html#giant.ray_tracer.scene.Scene" title="giant.ray_tracer.scene.Scene"><em>giant.ray_tracer.scene.Scene</em></a>) – The <a class="reference internal" href="../../../ray_tracer/scene/giant.ray_tracer.scene.Scene.html#giant.ray_tracer.scene.Scene" title="giant.ray_tracer.scene.Scene"><code class="xref py py-class docutils literal notranslate"><span class="pre">Scene</span></code></a> object containing the target, light, and obscuring objects.</p></li>
<li><p><strong>camera</strong> (<a class="reference internal" href="../../../camera/giant.camera.Camera.html#giant.camera.Camera" title="giant.camera.Camera"><em>giant.camera.Camera</em></a>) – The <a class="reference internal" href="../../../camera/giant.camera.Camera.html#giant.camera.Camera" title="giant.camera.Camera"><code class="xref py py-class docutils literal notranslate"><span class="pre">Camera</span></code></a> object containing the camera model and images to be utilized</p></li>
<li><p><strong>image_processing</strong> (<a class="reference internal" href="../../../image_processing/giant.image_processing.ImageProcessing.html#giant.image_processing.ImageProcessing" title="giant.image_processing.ImageProcessing"><em>giant.image_processing.ImageProcessing</em></a>) – The <a class="reference internal" href="../../../image_processing/giant.image_processing.ImageProcessing.html#giant.image_processing.ImageProcessing" title="giant.image_processing.ImageProcessing"><code class="xref py py-class docutils literal notranslate"><span class="pre">ImageProcessing</span></code></a> object to be used to process the images</p></li>
<li><p><strong>use_apparent_area</strong> (<em>bool</em>) – A boolean flag specifying whether to predict the minimum apparent area we should
consider when segmenting the image into foreground/background objects.</p></li>
<li><p><strong>apparent_area_margin_of_safety</strong> (<em>numbers.Real</em>) – The margin of safety we will use to decrease the predicted apparent area
to account for errors in the a priori scene/shape model as well as errors
introduced by assuming a spherical object.  The predicted apparent area
will be divided by this number and then supplied as the
<code class="xref py py-attr docutils literal notranslate"><span class="pre">minimum_segment_area</span></code> attribute.  This should
always be &gt;= 1.</p></li>
<li><p><strong>search_distance</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) – The search radius to search around the predicted centers for the observed centers of
the target objects.  This is used as a limit, so that if the closest segmented object to
a predicted target location is greater than this then the target is treated as not
found.  Additionally, if multiple segmented regions fall within this distance of the
target then we treat it as ambiguous and not found.</p></li>
<li><p><strong>apply_phase_correction</strong> (<em>bool</em>) – A boolean flag specifying whether to apply the phase correction to the observed
center of brightness to get closer to the center of figure based on the predicted
apparent diameter of the object.</p></li>
<li><p><strong>phase_correction_type</strong> (<em>Union</em><em>[</em><a class="reference internal" href="../unresolved/giant.relative_opnav.estimators.unresolved.PhaseCorrectionType.html#giant.relative_opnav.estimators.unresolved.PhaseCorrectionType" title="giant.relative_opnav.estimators.unresolved.PhaseCorrectionType"><em>giant.relative_opnav.estimators.unresolved.PhaseCorrectionType</em></a><em>, </em><em>str</em><em>]</em>) – The type of phase correction to use.  Should be one of the PhaseCorrectionType
enum values</p></li>
<li><p><strong>brdf</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="../../../ray_tracer/illumination/giant.ray_tracer.illumination.IlluminationModel.html#giant.ray_tracer.illumination.IlluminationModel" title="giant.ray_tracer.illumination.IlluminationModel"><em>giant.ray_tracer.illumination.IlluminationModel</em></a><em>]</em>) – The illumination model to use to compute the illumination values if the <code class="docutils literal notranslate"><span class="pre">RASTERED</span></code> phase
correction type is used.  If the <code class="docutils literal notranslate"><span class="pre">RASTERED</span></code> phase correction type is not used this is ignored.
If this is left as <code class="docutils literal notranslate"><span class="pre">None</span></code> and the <code class="docutils literal notranslate"><span class="pre">Rastered</span></code> phase correction type is used, this will default
to the McEwen Model, <a class="reference internal" href="../../../ray_tracer/illumination/giant.ray_tracer.illumination.McEwenIllumination.html#giant.ray_tracer.illumination.McEwenIllumination" title="giant.ray_tracer.illumination.McEwenIllumination"><code class="xref py py-class docutils literal notranslate"><span class="pre">McEwenIllumination</span></code></a>.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="giant.relative_opnav.estimators.moment_algorithm.MomentAlgorithm.technique">
<span class="sig-name descname"><span class="pre">technique</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'moment_algorithm'</span></em><a class="headerlink" href="#giant.relative_opnav.estimators.moment_algorithm.MomentAlgorithm.technique" title="Permalink to this definition">¶</a></dt>
<dd><p>The name of the technique identifier in the <a class="reference internal" href="../../relnav_class/giant.relative_opnav.relnav_class.RelativeOpNav.html#giant.relative_opnav.relnav_class.RelativeOpNav" title="giant.relative_opnav.relnav_class.RelativeOpNav"><code class="xref py py-class docutils literal notranslate"><span class="pre">RelativeOpNav</span></code></a> class.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="giant.relative_opnav.estimators.moment_algorithm.MomentAlgorithm.observable_type">
<span class="sig-name descname"><span class="pre">observable_type</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../estimator_interface_abc/giant.relative_opnav.estimators.estimator_interface_abc.RelNavObservablesType.html#giant.relative_opnav.estimators.estimator_interface_abc.RelNavObservablesType" title="giant.relative_opnav.estimators.estimator_interface_abc.RelNavObservablesType"><span class="pre">giant.relative_opnav.estimators.estimator_interface_abc.RelNavObservablesType</span></a><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">[&lt;RelNavObservablesType.CENTER_FINDING:</span> <span class="pre">'CENTER-FINDING'&gt;]</span></em><a class="headerlink" href="#giant.relative_opnav.estimators.moment_algorithm.MomentAlgorithm.observable_type" title="Permalink to this definition">¶</a></dt>
<dd><p>The type of observables this technique generates.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="giant.relative_opnav.estimators.moment_algorithm.MomentAlgorithm.camera">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">camera</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="../../../camera/giant.camera.Camera.html#giant.camera.Camera" title="giant.camera.Camera"><span class="pre">giant.camera.Camera</span></a></em><a class="headerlink" href="#giant.relative_opnav.estimators.moment_algorithm.MomentAlgorithm.camera" title="Permalink to this definition">¶</a></dt>
<dd><p>The camera instance that represents the camera used to take the images we are performing Relative OpNav on.</p>
<p>This is the source of the camera model, and may be used for other information about the camera as well.
See the <a class="reference internal" href="../../../camera/giant.camera.Camera.html#giant.camera.Camera" title="giant.camera.Camera"><code class="xref py py-class docutils literal notranslate"><span class="pre">Camera</span></code></a> property for details.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="giant.relative_opnav.estimators.moment_algorithm.MomentAlgorithm.scene">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">scene</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="../../../ray_tracer/scene/giant.ray_tracer.scene.Scene.html#giant.ray_tracer.scene.Scene" title="giant.ray_tracer.scene.Scene"><span class="pre">giant.ray_tracer.scene.Scene</span></a></em><a class="headerlink" href="#giant.relative_opnav.estimators.moment_algorithm.MomentAlgorithm.scene" title="Permalink to this definition">¶</a></dt>
<dd><p>The scene which defines the a priori locations of all targets and light sources with respect to the camera.</p>
<p>You can assume that the scene has been updated for the appropriate image time inside of the class.</p>
</dd></dl>

</dd></dl>

<p class="rubric">Summary of Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="giant.relative_opnav.estimators.moment_algorithm.MomentAlgorithm.compute_line_of_sight_sun_image.html#giant.relative_opnav.estimators.moment_algorithm.MomentAlgorithm.compute_line_of_sight_sun_image" title="giant.relative_opnav.estimators.moment_algorithm.MomentAlgorithm.compute_line_of_sight_sun_image"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute_line_of_sight_sun_image</span></code></a></p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="giant.relative_opnav.estimators.moment_algorithm.MomentAlgorithm.compute_phase_correction.html#giant.relative_opnav.estimators.moment_algorithm.MomentAlgorithm.compute_phase_correction" title="giant.relative_opnav.estimators.moment_algorithm.MomentAlgorithm.compute_phase_correction"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute_phase_correction</span></code></a></p></td>
<td><p>The method computes the phase correction assuming a spherical target.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="giant.relative_opnav.estimators.moment_algorithm.MomentAlgorithm.estimate.html#giant.relative_opnav.estimators.moment_algorithm.MomentAlgorithm.estimate" title="giant.relative_opnav.estimators.moment_algorithm.MomentAlgorithm.estimate"><code class="xref py py-obj docutils literal notranslate"><span class="pre">estimate</span></code></a></p></td>
<td><p>This method extracts the observed center of figure for each requested target object from the supplied image.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="giant.relative_opnav.estimators.moment_algorithm.MomentAlgorithm.rastered_phase_correction.html#giant.relative_opnav.estimators.moment_algorithm.MomentAlgorithm.rastered_phase_correction" title="giant.relative_opnav.estimators.moment_algorithm.MomentAlgorithm.rastered_phase_correction"><code class="xref py py-obj docutils literal notranslate"><span class="pre">rastered_phase_correction</span></code></a></p></td>
<td><p>This method computes the phase correction by raster rendering the target to determine the offset from the center of illumination to the center of figure.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="giant.relative_opnav.estimators.moment_algorithm.MomentAlgorithm.reset.html#giant.relative_opnav.estimators.moment_algorithm.MomentAlgorithm.reset" title="giant.relative_opnav.estimators.moment_algorithm.MomentAlgorithm.reset"><code class="xref py py-obj docutils literal notranslate"><span class="pre">reset</span></code></a></p></td>
<td><p>This method resets the observed/computed attributes as well as the details attribute to have <code class="docutils literal notranslate"><span class="pre">None</span></code> for each target in <code class="xref py py-attr docutils literal notranslate"><span class="pre">scene</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="giant.relative_opnav.estimators.moment_algorithm.MomentAlgorithm.simple_phase_correction.html#giant.relative_opnav.estimators.moment_algorithm.MomentAlgorithm.simple_phase_correction" title="giant.relative_opnav.estimators.moment_algorithm.MomentAlgorithm.simple_phase_correction"><code class="xref py py-obj docutils literal notranslate"><span class="pre">simple_phase_correction</span></code></a></p></td>
<td><p>This method computes the simple phase correction assuming the target is a sphere.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="giant.relative_opnav.estimators.moment_algorithm.MomentAlgorithm.target_generator.html#giant.relative_opnav.estimators.moment_algorithm.MomentAlgorithm.target_generator" title="giant.relative_opnav.estimators.moment_algorithm.MomentAlgorithm.target_generator"><code class="xref py py-obj docutils literal notranslate"><span class="pre">target_generator</span></code></a></p></td>
<td><p>This method returns a generator which yields target_index, target pairs that are to be processed based on the input <code class="docutils literal notranslate"><span class="pre">include_targets</span></code>.</p></td>
</tr>
</tbody>
</table>
<div class="line-block">
<div class="line"><br /></div>
</div>
</section>


          </div>
              <div class="related bottom">
                &nbsp;
  <nav id="rellinks">
    <ul>
        <li>
          &larr;
          <a href="../giant.relative_opnav.estimators.moment_algorithm.html" title="Previous document">moment_algorithm</a>
        </li>
        <li>
          <a href="giant.relative_opnav.estimators.moment_algorithm.MomentAlgorithm.compute_line_of_sight_sun_image.html" title="Next document">MomentAlgorithm.compute_line_of_sight_sun_image</a>
          &rarr;
        </li>
    </ul>
  </nav>
              </div>
          
        </div>
      </div>
    <div class="clearer"></div>
  </div>
    <div class="footer">
      &copy;2021 United States Government.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 4.3.2</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="../../../_sources/relative_opnav/estimators/moment_algorithm/giant.relative_opnav.estimators.moment_algorithm.MomentAlgorithm.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>